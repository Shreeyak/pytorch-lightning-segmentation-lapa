# @package _group_
name: trainer
gpus: "0"
overfit_batches: 0.0
distributed_backend: "ddp"
num_nodes: 1
precision: 32
limit_train_batches: 1.0
limit_val_batches: 1.0
limit_test_batches: 1.0
fast_dev_run: True
